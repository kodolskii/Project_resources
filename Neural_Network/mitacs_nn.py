# -*- coding: utf-8 -*-
"""MITACS_NN.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1bUZkQI17QOq717qCLHTKHrNDtVQuDDvg
"""

# -*- coding: utf-8 -*-
"""Copy_of_GNN_PyTorch.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1s5LYBTB-jq2KGP1ekvSctIfieAMJD0BX
"""

import os
import matplotlib.pyplot as plt
import numpy as np
!pip install mat4py

!pip3 install torch
!pip3 install torch-geometric

import torch
import torch.nn as nn
import torch.nn.functional as F
import torchvision
import torchvision.transforms as transforms
import torch_geometric
import math
from mat4py import loadmat
from torch_geometric.data import Data
from torch_geometric.data import Data
from torch_geometric.loader import DataLoader
from torch_geometric.data import Dataset
from torch.nn import Linear
import torch.nn.functional as F
from torch_geometric.nn import GCNConv
from torch_geometric.nn import global_mean_pool
from torch_geometric.nn import GATConv
from torch_geometric.nn import NNConv
from torch_geometric.data import InMemoryDataset
from torch_geometric.data import collate
from torch_geometric.nn import BatchNorm

x = loadmat('/content/drive/MyDrive/GNN_Files/neighbours.mat')

neighbours = np.array(x['neighbours'])

y = open('/content/drive/MyDrive/GNN_Files/neb_output.txt')
f = []
atoms = []
energy = []
for row in y:
    f.append([float(x) for x in row.split()])
for i in range(len(f)):
    atoms.append(int(f[i][1]))
    energy.append(f[i][8])

print(energy[0])

y = open('/content/drive/MyDrive/GNN_Files/readhea-genR10_50x50x50_NEB_255101_NN0.txt')
ratoms = []
for row in y:
    ratoms.append([float(x) for x in row.split()])

#coulomb matrix function
def coulomb(p,q,dist):
    a = ratoms[p-1][1]
    b = ratoms[q-1][1]
    if a == 1:
        q1 = 1.91
    if a == 2:
        q1 = 1.83
    if a == 3:
        q1 = 1.66
    if a == 4:
        q1 = 1.88
    if b == 1:
        q2 = 1.91
    if b == 2:
        q2 = 1.83
    if b == 3:
        q2 = 1.66
    if b == 4:
        q2 = 1.88
    x = (q1*q2)/(dist*dist)
    return x

#Func to calculate distance
def dist(a,b):
    d = math.sqrt(((ratoms[a-1][2]-ratoms[b-1][2])**2)+((ratoms[a-1][3]-ratoms[b-1][3])**2)+((ratoms[a-1][4]-ratoms[b-1][4])**2))
    return d

atomlist = []
atomidlist = []
for i in range(len(atoms)):
  atomlist.append([ratoms[atoms[i]-1][1]])
  atomidlist.append([atoms[i]])
  for j in range(len(neighbours[(atoms[i]-1)])):
    atomlist[i].append(ratoms[neighbours[atoms[i]-1][j]-1][1])
    atomidlist[i].append(neighbours[atoms[i]-1][j])

distmat = []
coulombmat = []
degree = np.zeros((55,55))
for i in range(len(atoms)):
  mat1 = np.zeros((55,55))
  mat2 = np.zeros((55,55))
  for j in range(len(atomidlist[i])):
    for k in range(len(atomidlist[i])):
      d  = dist(atomidlist[i][j],atomidlist[i][k])
      if d<3.7:
        if j!=k:
          mat1[j][k] = 1/d
          mat1[k][j] = 1/d
          mat2[j][k] = coulomb(atomidlist[i][j],atomidlist[i][k],d)
          mat2[k][j] = coulomb(atomidlist[i][j],atomidlist[i][k],d)
  distmat.append(mat1)
  coulombmat.append(mat2)

D = []
for i in range(len(coulombmat)):
  degree = np.zeros((55,55))
  for j in range(len(coulombmat[i])):
    count = 0
    for k in range(len(coulombmat[i][j])):
      if coulombmat[i][j][k]!=0:
        count+=1
    degree[j][j] = count
  D.append(degree)

coulombmat[404][44]



# for i in range(len(D[404])):
#   print(D[404][i])
error = []
for i in range(len(D)):
  for j in range(len(D[i])):
    flag = 0
    for k in range(len(D[i][j])):
      if D[i][j][k]!=0:
        flag = 1
    if flag == 0:
      error.append(i)

print(error)
len(energy)

D.pop(404)
D.pop(3161)
D.pop(3162)
energy.pop(404)
energy.pop(3161)
energy.pop(3162)

np.linalg.inv(D[3162])

from scipy.linalg import fractional_matrix_power
L = []
tp = 0
for i in range(len(D)):
  tp+=1
  dhalf = fractional_matrix_power((np.linalg.inv(D[i])), 0.5)
  lap = np.matmul(dhalf,coulombmat[i])
  lapla = np.matmul(lap,dhalf)
  L.append(lapla)

from numpy import linalg as LA
eigenvalues = []
eigenvectors = []
for i in (L):
  val,vec = LA.eig(i)
  eigenvalues.append(val)
  eigenvectors.append(vec)

x = [4,1,2,3,8,6,7,5]
print(np.argsort(x))

eigvalue = []
eigvec = []
y = []

for i in range(len(eigenvalues)):
  eigvec = [eigenvectors[i][x] for x in np.argsort(eigenvectors[i])]
  eigvalue = sorted(eigenvalues[i])

plot = [eigenvalues[i][0] for i in range(len(eigenvalues))]
print(len(plot))
plt.hist(plot, bins = 100)
plt.show

data = []
for i in range(len(eigenvalues)):
  data.append(eigenvalues[i])
  data[i] = np.concatenate((data[i],np.ndarray.flatten(eigenvectors[i])))

import tensorflow.keras as keras
from keras import layers,models
import tensorflow as tf
import numpy as np
import pickle
import pandas as pd
from sklearn.preprocessing import OneHotEncoder
from keras.layers import BatchNormalization

len(data)
# len(energy)

for i in range(len(data)):
  data[i] = np.append(data[i],energy[i])

len(data[0])

np.random.shuffle(data)
train = data[0:3573]
valid = data[3573:4338]
test = data[4338:]
trainy = [train[i][-1] for i in range(len(train))]
trainx = [train[i][0:(len(train[i])-1)] for i in range(len(train))]
validy = [valid[i][-1] for i in range(len(valid))]
validx = [valid[i][0:(len(valid[i])-1)] for i in range(len(valid))]
testy = [test[i][-1] for i in range(len(test))]
testx = [test[i][0:(len(test[i])-1)] for i in range(len(test))]

trainx = np.array(trainx)
trainy = np.array(trainy)
validx = np.array(validx)
validy = np.array(validy)
testx = np.array(testx)
testy = np.array(testy)



model = models.Sequential()
model.add(layers.Dense(5,activation = 'relu',kernel_initializer='random_normal'))
model.add(BatchNormalization())
model.add(layers.Dense(5,activation = 'relu'))
model.add(BatchNormalization())
model.add(layers.Dense(5,activation = 'relu'))

# model.add(layers.Dense(20,activation = 'relu'))

# model.add(layers.Dense(20,activation = 'relu'))

# model.add(layers.Dense(20,activation = 'relu'))
tf.keras.layers.Dropout(0.1)
model.add(layers.Dense(1))

adam = keras.optimizers.Adam(learning_rate = 0.001)
model.compile(optimizer = 'adam',loss = tf.keras.losses.MeanSquaredError())
history = model.fit(trainx,trainy,batch_size = 32, epochs = 100,validation_data=(validx,validy))

trainloss = history.history['loss']
val_loss = history.history['val_loss']
epochs = range(1,len(trainloss)+1)

import matplotlib.pyplot as plt
plt.plot(epochs,trainloss, label = "Training Loss")
plt.plot(epochs,val_loss, label = "Validation Loss")
leg = plt.legend(loc='upper center')
plt.show

x = model.predict(testx)

pred = []
for i in range(len(x)):
  pred.append(float(x[i][0]))

numcorrect = 0
prederror = []
for i in range(len(pred)):
  prederror.append(abs(pred[i]-testy[i]))
  if (prederror[i])<0.05:
    numcorrect += 1
accuracy = numcorrect/len(testy)
print(accuracy)

plt.scatter(testy,pred)

