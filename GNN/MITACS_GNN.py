# -*- coding: utf-8 -*-
"""Copy_of_GNN_PyTorch.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1s5LYBTB-jq2KGP1ekvSctIfieAMJD0BX
"""

import os
import matplotlib.pyplot as plt
import numpy as np
!pip install mat4py

!pip3 install torch
!pip3 install torch-geometric

import torch
import torch.nn as nn
import torch.nn.functional as F
import torchvision
import torchvision.transforms as transforms
import torch_geometric
import math
from mat4py import loadmat
from torch_geometric.data import Data
from torch_geometric.data import Data
from torch_geometric.loader import DataLoader
from torch_geometric.data import Dataset
from torch.nn import Linear
import torch.nn.functional as F
from torch_geometric.nn import GCNConv
from torch_geometric.nn import global_mean_pool
from torch_geometric.nn import GATConv
from torch_geometric.nn import NNConv
from torch_geometric.data import InMemoryDataset
from torch_geometric.data import collate
from torch_geometric.nn import BatchNorm

x = loadmat('/content/drive/MyDrive/GNN_Files/neighbours.mat')

neighbours = np.array(x['neighbours'])

y = open('/content/drive/MyDrive/GNN_Files/neb_output.txt')
f = []
atoms = []
energy = []
for row in y:
    f.append([float(x) for x in row.split()])
for i in range(len(f)):
    atoms.append(int(f[i][1]))
    energy.append(f[i][8])

print(energy[0])

y = open('/content/drive/MyDrive/GNN_Files/readhea-genR10_50x50x50_NEB_255101_NN0.txt')
ratoms = []
for row in y:
    ratoms.append([float(x) for x in row.split()])



#coulomb matrix function
def coulomb(p,q,dist):
    a = ratoms[p-1][1]
    b = ratoms[q-1][1]
    if a == 1:
        q1 = 1.91
    if a == 2:
        q1 = 1.83
    if a == 3:
        q1 = 1.66
    if a == 4:
        q1 = 1.88
    if b == 1:
        q2 = 1.91
    if b == 2:
        q2 = 1.83
    if b == 3:
        q2 = 1.66
    if b == 4:
        q2 = 1.88
    x = (q1*q2)/dist
    return x

#Func to calculate distance
def dist(a,b):
    d = math.sqrt(((ratoms[a-1][2]-ratoms[b-1][2])**2)+((ratoms[a-1][3]-ratoms[b-1][3])**2)+((ratoms[a-1][4]-ratoms[b-1][4])**2))
    return d

atomlist = []
atomidlist = []
for i in range(len(atoms)):
  atomlist.append([ratoms[atoms[i]-1][1]])
  atomidlist.append([atoms[i]])
  for j in range(len(neighbours[(atoms[i]-1)])):
    atomlist[i].append(ratoms[neighbours[atoms[i]-1][j]-1][1])
    atomidlist[i].append(neighbours[atoms[i]-1][j])

print(len(atomlist[25]))

valuematrix = np.zeros((4,4))
a = 0
for i in range(len(valuematrix)):
  for j in range(len(valuematrix[i])):
    if valuematrix[i][j] == 0:
      valuematrix[i][j] = a
      valuematrix[j][i] = a
      a+=1
# 1,1 = 0
# 1,2 = 1
# 1,3 = 2
# 1,4 = 3
# 2,1 = 1
# 2,2 = 4
# 2,3 = 5
# 2,4 = 6
# 3,1 = 2
# 3,2 = 5
# 3,3 = 7
# 3,4 = 8
# 4,1 = 3
# 4,2 = 6
# 4,3 = 8
# 4,4 = 9
print(valuematrix[0][3])

one_hot_number_matrix = []
for i in range(len(atomlist)):
  mat3 = np.zeros((55,55))
  for a in range(len(mat3)):
    for b in range(len(mat3[a])):
      mat3[a][b] = -1
  for j in range(len(atomlist[i])):
    for k in range(len(atomlist[i])):
      d  = dist(atomidlist[i][j],atomidlist[i][k])
      if d<3.7:
        if j!= k and mat3[j][k] == -1:
          mat3[j][k] = valuematrix[int(atomlist[i][j]-1)][int(atomlist[i][j]-1)]
          mat3[k][j] = valuematrix[int(atomlist[i][j]-1)][int(atomlist[i][j]-1)]
  one_hot_number_matrix.append(mat3)

# np.unique(one_hot_number_matrix[7])

distmat = []
coulombmat = []
for i in range(len(atoms)):
  mat1 = np.zeros((55,55))
  mat2 = np.zeros((55,55))
  for j in range(len(atomidlist[i])):
    for k in range(len(atomidlist[i])):
      d  = dist(atomidlist[i][j],atomidlist[i][k])
      if d<3.7:
        if j!=k:
          mat1[j][k] = 1/d
          mat1[k][j] = 1/d
          mat2[j][k] = coulomb(atomidlist[i][j],atomidlist[i][k],d)
          mat2[k][j] = coulomb(atomidlist[i][j],atomidlist[i][k],d)
  distmat.append(mat1)
  coulombmat.append(mat2)



# import torch

# # Convert distmat to PyTorch tensor
# distmat_tensor = torch.tensor(distmat)

# # Get the number of unique distance values
# num_dist_values = int(torch.max(distmat_tensor).item()) + 1

# # Perform one-hot encoding
# distmat_onehot = torch.nn.functional.one_hot(distmat_tensor.long(), num_classes=num_dist_values)

# # Convert the one-hot encoded tensor back to numpy array
# distmat_onehot = distmat_onehot.numpy()

# np.unique(distmat_onehot)
# print(num_dist_values)

z = [1,2,3,4,5,6,7,8,9,10]
z = (z-np.min(z))/(np.max(z)-np.min(z))
print(z)

from numpy import linalg as LA
eigenvalues = []
eigenvectors = []
for i in (coulombmat):
  val,vec = LA.eig(i)
  eigenvalues.append(val)
  eigenvectors.append(vec)

plotvalues = []
for i in range(len(eigenvalues)):
  plotvalues.append(eigenvalues[i][0])
plt.hist(plotvalues, bins = 50)
plt.xlabel("1st Eigenvalue of all examples")
plt.show

for a in range(0,55):
  import matplotlib.pyplot as plt
  plotvalues = []
  for i in range(len(eigenvalues)):
    plotvalues.append(eigenvalues[i][a])
  plt.hist(plotvalues, bins = 50)
  plt.xlabel("Every eigenvalue of all examples")
  plt.show

smallest = []
for i in range(len(eigenvalues)):
  s = min(eigenvalues[i])
  smallest.append(s)
plt.hist(smallest, bins = 100)
plt.xlabel("Smallest eigenvalue")
plt.show

def angle(arr1,arr2):
  dotprod = 0
  valuearr1 = 0
  valuearr2 = 0
  for i in range(len(arr1)):
    dotprod += arr1[i]*arr2[i]
    valuearr1 += arr1[i]*arr1[i]
    valuearr2 += arr2[i]*arr2[i]
  valuearr1 = math.sqrt(valuearr1)
  valuearr2 = math.sqrt(valuearr2)
  cos = dotprod/(abs(valuearr1)*abs(valuearr2))
  theta = np.arccos(cos)
  return theta

eigvecangles = []
plotvalues = []
for i in range(len(eigenvectors)):
  plotvalues.append(eigenvalues[i])
  eigvecangles.append(angle(eigenvectors[0][0],eigenvectors[i][0]))
plt.hist(eigvecangles, bins = 100)
plt.xlabel("Angle between 1st eigenvector of 1st example and 1st eigenvector of all respective examples")
plt.ylabel("no. of angles")
plt.show

def dotproduct(ar1,ar2):
  dotp = 0
  for i in range(len(ar1)):
    dotp += ar1[i]*ar2[i]
  return dotp

def grammatrix(list):
  gm = np.zeros((len(list),len(list)))
  for i in range(0,len(list)):
    for j in range(0,len(list)):
      gm[i][j] = dotproduct(list[i],list[j])
  return gm

(grammatrix(eigenvectors[0])).shape

grammatrix(eigenvectors[0])

a = np.array([2,2,3,4,2])
b = 4
a = np.append(a,b)
print(a)

p = atomlist[4]
 print(p)

data_list = []
for i in range(len(atomlist)):
  edge_feature = []
  for a in range(len(distmat[i])):
    sum = 0
    for b in range(len(distmat[i][a])):
      sum += distmat[i][a][b]
    avg = sum/len(distmat[i][a])
    edge_feature.append(avg)
  # edge_feature = np.array(edge_feature)
  # edge_feature = torch.tensor(edge_feature)
  c = []
  for j in range(len(atomlist[i])):
    c.append([atomlist[i][j]])
  # print(c)
  # c = atomlist[i]
  # c = c.reshape((-1,1))
  # c = c-1
  # c = torch.nn.functional.one_hot(c,num_classes = 4).float()
  # c = np.array(c)
  # edge_feature = edge_feature.reshape((55,1))
  # print(c.shape,edge_feature.shape)
  for e in range(len(c)):
    # c[e] = np.append(c[e],edge_feature[e])
    c[e].append(edge_feature[e])
  c = torch.tensor(c).float()
  x = c

  # x = torch.cat((c,edge_feature))
  y = torch.tensor(energy[i], dtype = torch.float)
  source = []
  target = []
  edge_attr = []
  for j in range(len(distmat[0])):
    for k in range(len(distmat[0][j])):
      if distmat[i][j][k]!=0:
        source.append(j)
        # source.append(k)
        target.append(k)
        # target.append(j)
        # edge_weight.append(coulombmat[i][j][k])
        edge_attr.append([coulombmat[i][j][k]])
  edge = [source,target]
  edge_index = torch.tensor([source,target])

  edge_attr = torch.tensor(edge_attr, dtype = torch.float)
  if len(edge_index[0])==612:
    data_list.append(Data(x=x,y=y,edge_index = edge_index,edge_attr = edge_attr))

data_list

import networkx as nx
g = torch_geometric.utils.to_networkx(data_list[50], to_undirected=True)
nx.draw(g)

n = np.arange(4556)
np.random.shuffle(n)

train = []
train_y = []
valid = []
valid_y = []
test = []
test_y = []
for i in range(0,3189):
  train.append(data_list[n[i]])

for i in range(3189,4556):
  valid.append(data_list[n[i]])

train_loader = DataLoader(train, batch_size = 64, shuffle=True)
valid_loader = DataLoader(valid, batch_size = 64)

train_loader.dataset.__getitem__(4).x.shape

dataset,slices = torch_geometric.data.InMemoryDataset.collate(data_list)

print(dataset.x.shape)



class GCN(torch.nn.Module):
    def __init__(self, hidden_channels):
        super(GCN, self).__init__()
        self.conv = []
        self.conv1 = GCNConv(dataset.num_features, hidden_channels)
        self.conv2 = GCNConv(hidden_channels,hidden_channels)
        self.conv3 = GCNConv(hidden_channels,hidden_channels)
        self.conv4 = GCNConv(hidden_channels,hidden_channels)
        self.conv5 = GCNConv(hidden_channels,hidden_channels)
        # for i in range(0,5):
        #   self.conv.append(GCNConv(hidden_channels, hidden_channels))
        # self.conv2 = GCNConv(hidden_channels, hidden_channels)
        # self.conv3 = GCNConv(hidden_channels, hidden_channels)
        # self.conv4 = GCNConv(hidden_channels, hidden_channels)
        # self.conv5 = GCNConv(hidden_channels, hidden_channels)
        self.flat = torch.nn.Flatten()
        self.BN = BatchNorm(hidden_channels)
        self.lin = Linear(hidden_channels, 1)

    def forward(self, x, edge_index, edge_weight, batch):

        # 1. Obtain node embeddings
        x = self.conv1(x, edge_index, edge_weight)
        x = self.BN(x)
        x = x.relu()
        x = self.conv2(x, edge_index, edge_weight)
        x = self.BN(x)
        x = x.relu()
        x = self.conv3(x, edge_index, edge_weight)
        x = self.BN(x)
        x = x.relu()
        x = self.conv4(x, edge_index, edge_weight)
        x = self.BN(x)
        x = x.relu()
        x = self.conv5(x, edge_index, edge_weight)
        x = self.BN(x)
        x = x.relu()


        # for i in range(0,5):
        #   x = self.conv[i](x, edge_index, edge_weight)
        #   x = x.relu()

        # x = self.conv2(x, edge_index, edge_attr)
        # x = x.relu()
        # x = self.conv3(x, edge_index, edge_attr)
        # x = x.relu()
        # x = self.conv4(x, edge_index, edge_attr)
        # x = x.relu()
        # x = self.conv5(x, edge_index, edge_attr)
        # x = x.relu()

        # 2. Readout layer
        x = global_mean_pool(x,batch)  # [batch_size, hidden_channels]

        # 3. Apply a final classifier
        # x = F.dropout(x, p=0.1, training=self.training)
        x = self.lin(x)

        return x

model = GCN( hidden_channels=64)
print(model)

optimizer = torch.optim.Adam(model.parameters(), lr = 0.00001)
criterion = torch.nn.MSELoss()

# for step, data in enumerate(train_loader):
#     print(f'Step {step + 1}:')
#     print('=======')
#     print(f'Number of graphs in the current batch: {data.num_graphs}')
#     print(data)
#     print()

loss =None
def train_model(train_loader):
    model.train()
    for  data in train_loader:
      # print(data.x.shape, data.edge_index.shape, data.edge_attr.shape)
      data.x = data.x.reshape((-1,2))
      data.y = data.y.reshape((-1,1))
      optimizer.zero_grad()
      # print(data.x.shape, data.edge_index.shape, data.edge_attr.shape)
      out = model(data.x, data.edge_index, data.edge_weight, data.batch)

      # loss = F.mse_loss(out,data.y)
      # loss.backward()
      loss = criterion(out,data.y)
      loss.backward()
      optimizer.step()
    return float(loss)

def test(loader):
    model.eval()
    correct = 0
    for data in loader:
      data.x = data.x.reshape((-1,2))
      pred = model(data.x, data.edge_index, data.edge_weight, data.batch)
      data.y = data.y.reshape((-1,1))
      correct += torch.sum(abs((pred)-(data.y)) < 0.05)
      SSr = torch.sum(((pred)-(data.y))**2)
      mean = torch.mean(data.y)
      SStot = torch.sum(((data.y)-(mean))**2)
      correct = correct/len(loader.dataset)
      R2 = 1 - (SSr/SStot)
      #accs = []
      #for mask in [data.train_mask, data.val_mask, data.test_mask]:
          #accs.append(int((pred[mask] == data.y[mask]).sum()) / int(mask.sum()))
      return R2

Loss = []
for epoch in range(0,150):
  loss = train_model(train_loader)

  train_acc = test(train_loader)
  valid_acc = test(valid_loader)
  scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=50, gamma=0.1)
  Loss.append(loss)
  print(f'Epoch: {epoch:03d}, Train Acc: {train_acc:.4f}, Train Loss: {loss:.4f}, Valid Acc: {valid_acc:.4f}')

b = torch.tensor([2,3,4])
a = torch.tensor([0,1,2])
import numpy as np
print(torch.sum((b-a)**2))

